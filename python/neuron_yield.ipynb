{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what's the neuron yield across probes, experimenters and recording sites?\n",
    "Anne Urai & Nate Miska, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting anneurai@datajoint.internationalbrainlab.org:3306\n"
     ]
    }
   ],
   "source": [
    "# GENERAL THINGS FOR COMPUTING AND PLOTTING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, time\n",
    "import scipy as sp\n",
    "\n",
    "# visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ibl specific things\n",
    "import datajoint as dj\n",
    "from ibl_pipeline import reference, subject, action, acquisition, data, behavior\n",
    "from ibl_pipeline.analyses import behavior as behavior_analysis\n",
    "ephys = dj.create_virtual_module('ephys', 'ibl_ephys')\n",
    "figpath = os.path.join(os.path.expanduser('~'), 'Data/Figures_IBL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. neuron yield per lab and Npix probe over time\n",
    "Replicates https://github.com/int-brain-lab/analysis/blob/master/python/probe_performance_over_sessions.py using DJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataJointError",
     "evalue": "Attribute `probe_serial_number` is not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataJointError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-203a58783849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m probe_insertions = probe_insertions.proj('probe_serial_number', 'probe_model_name', 'lab_name', 'metrics',\n\u001b[1;32m      6\u001b[0m                                          \u001b[0;34m'good_enough_for_brainwide_map'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                          session_date='DATE(session_start_time)')\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mclusts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobe_insertions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/iblenv/lib/python3.6/site-packages/datajoint/expression.py\u001b[0m in \u001b[0;36mproj\u001b[0;34m(self, *attributes, **named_attributes)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mattr\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mexcluded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0malready\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mignored\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \"\"\"\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mProjection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamed_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_all_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnamed_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/iblenv/lib/python3.6/site-packages/datajoint/expression.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, arg, attributes, named_attributes, include_primary_key)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamed_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestriction\u001b[0m  \u001b[0;31m# copy restriction when no subquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/iblenv/lib/python3.6/site-packages/datajoint/heading.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(self, attribute_list, named_attributes, force_primary_key)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \"\"\"\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# check for missing attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataJointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attribute `%s` is not found'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattribute_list\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnamed_attributes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataJointError\u001b[0m: Attribute `probe_serial_number` is not found"
     ]
    }
   ],
   "source": [
    "probe_insertions = ephys.ProbeInsertion * ephys.DefaultCluster.Metrics * subject.SubjectLab \\\n",
    "                    * (acquisition.SessionProject\n",
    "                      & 'session_project = \"ibl_neuropixel_brainwide_01\"') \\\n",
    "                    * behavior_analysis.SessionTrainingStatus\n",
    "probe_insertions = probe_insertions.proj('probe_serial_number', 'probe_model_name', 'lab_name', 'metrics',\n",
    "                                         'good_enough_for_brainwide_map',\n",
    "                                         session_date='DATE(session_start_time)')\n",
    "clusts = probe_insertions.fetch(format='frame').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put metrics into df columns from the blob (feature request: can these be added as attributes instead?)\n",
    "for kix, k in enumerate(['ks2_label']):\n",
    "    tmp_var = []\n",
    "    for id, c in clusts.iterrows():\n",
    "        if k in c['metrics'].keys():\n",
    "            tmp = c['metrics'][k]\n",
    "        else:\n",
    "            tmp = np.nan\n",
    "        tmp_var.append(tmp)\n",
    "    clusts[k] = tmp_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hofer and mrsic-flogel probes are shared\n",
    "clusts['lab_name'] = clusts['lab_name'].str.replace('mrsicflogellab','swclab')\n",
    "clusts['lab_name'] = clusts['lab_name'].str.replace('hoferlab','swclab')\n",
    "clusts.lab_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts['probe_name'] = clusts['lab_name'] + ', ' + clusts['probe_model_name'] + ': ' + clusts['probe_serial_number']\n",
    "clusts_summ = clusts.groupby(['lab_name', 'probe_name', 'session_start_time', 'ks2_label'])['session_date'].count().reset_index()\n",
    "\n",
    "# use recording session number instead of date\n",
    "clusts_summ['recording'] = clusts_summ.groupby(['probe_name']).cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", context=\"paper\")\n",
    "g, axes = plt.subplots(6,6,figsize=(18,20))\n",
    "\n",
    "for probe, ax in zip(clusts_summ.probe_name.unique(), axes.flatten()):\n",
    "    df = clusts_summ[clusts_summ.probe_name==probe].groupby(['session_start_time','ks2_label']).session_date.sum()\n",
    "    df.unstack().plot.barh(ax=ax, stacked=True, legend=False, colormap='Pastel2')\n",
    "    ax.set_title(probe, fontsize=12)\n",
    "    ax.axvline(x=60, color='seagreen', linestyle=\"--\")\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_ylim([-1, np.max([max(ax.get_ylim()), 10])])\n",
    "    ax.set_xlim([0, 1000])\n",
    "    \n",
    "axes.flatten()[-1].set_axis_off()\n",
    "sns.despine(trim=True)   \n",
    "plt.tight_layout()\n",
    "plt.xlabel('Number of KS2 neurons')\n",
    "plt.ylabel('Recording session')\n",
    "g.savefig(os.path.join(figpath, 'probe_yield_oversessions.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. what is the overall yield of sessions, neurons etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overall distribution of neurons per session\n",
    "g = sns.FacetGrid(data=clusts_summ, hue='ks2_label', palette='Set2')\n",
    "g.map(sns.distplot, \"session_date\", bins=np.arange(10, 500, 15), hist=True, rug=False, kde=False).add_legend()\n",
    "for ax in g.axes.flatten():\n",
    "    ax.axvline(x=60, color='seagreen', linestyle=\"--\")\n",
    "    \n",
    "g.set_xlabels('Number of KS2 neurons')\n",
    "g.set_ylabels('Number of sessions')\n",
    "g.savefig(os.path.join(figpath, 'probe_yield_allrecs.pdf'))\n",
    "\n",
    "print('TOTAL YIELD SO FAR:')\n",
    "clusts.groupby(['ks2_label'])['ks2_label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overall distribution of neurons per session\n",
    "g = sns.FacetGrid(data=clusts_summ, hue='ks2_label', col_wrap=4, col='lab_name', palette='Set2')\n",
    "g.map(sns.distplot, \"session_date\", bins=np.arange(10, 500, 15), hist=True, rug=False, kde=False).add_legend()\n",
    "for ax in g.axes.flatten():\n",
    "    ax.axvline(x=60, color='seagreen', linestyle=\"--\")\n",
    "    \n",
    "g.set_xlabels('Number of KS2 neurons')\n",
    "g.set_ylabels('Number of sessions')\n",
    "#g.savefig(os.path.join(figpath, 'probe_yield_allrecs_perlab.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overall number of sessions that meet criteria for behavior and neural yield\n",
    "sessions = clusts.loc[clusts.ks2_label == 'good', :].groupby(['lab_name', 'subject_uuid', 'session_start_time', \n",
    "                           'good_enough_for_brainwide_map'])['cluster_id'].count().reset_index()\n",
    "sessions['enough_neurons'] = (sessions['cluster_id'] > 60)\n",
    "ct = sessions.groupby(['good_enough_for_brainwide_map', 'enough_neurons'])['cluster_id'].count().reset_index()\n",
    "print('total nr of sessions: %d'%ct.cluster_id.sum())\n",
    "pd.pivot_table(ct, columns=['good_enough_for_brainwide_map'], values=['cluster_id'], index=['enough_neurons'])\n",
    "#sessions.describe()\n",
    "# pd.pivot_table(df, values='cluster_id', index=['lab_name'],\n",
    "#                     columns=['enough_neurons'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that this pandas wrangling is correct...\n",
    "ephys_sessions = acquisition.Session * subject.Subject * subject.SubjectLab \\\n",
    "                    * (acquisition.SessionProject\n",
    "                      & 'session_project = \"ibl_neuropixel_brainwide_01\"') \\\n",
    "                    * behavior_analysis.SessionTrainingStatus \\\n",
    "                    & ephys.ProbeInsertion & ephys.DefaultCluster.Metrics \n",
    "ephys_sessions = ephys_sessions.fetch(format='frame').reset_index()\n",
    "# ephys_sessions\n",
    "# ephys_sessions.groupby(['good_enough_for_brainwide_map'])['session_start_time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which sessions do *not* show good enough behavior?\n",
    "ephys_sessions.loc[ephys_sessions.good_enough_for_brainwide_map == 0, :].groupby([\n",
    "                        'lab_name', 'subject_nickname', 'session_start_time'])['session_start_time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per lab, what's the drop-out due to behavior? \n",
    "ephys_sessions['good_enough_for_brainwide_map'] = ephys_sessions['good_enough_for_brainwide_map'].astype(int)\n",
    "ephys_sessions.groupby(['lab_name'])['good_enough_for_brainwide_map'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys_sessions['good_enough_for_brainwide_map'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per lab, what's the dropout due to yield?\n",
    "sessions['enough_neurons'] = sessions['enough_neurons'].astype(int)\n",
    "sessions.groupby(['lab_name'])['enough_neurons'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## also show the total number of neurons, only from good behavior sessions\n",
    "probe_insertions = ephys.ProbeInsertion * ephys.DefaultCluster.Metrics * subject.SubjectLab \\\n",
    "                    * (acquisition.SessionProject\n",
    "                      & 'session_project = \"ibl_neuropixel_brainwide_01\"') \\\n",
    "                    * (behavior_analysis.SessionTrainingStatus & \n",
    "                       'good_enough_for_brainwide_map = 1')\n",
    "probe_insertions = probe_insertions.proj('probe_serial_number', 'probe_model_name', 'lab_name', 'metrics',\n",
    "                                         'good_enough_for_brainwide_map',\n",
    "                                         session_date='DATE(session_start_time)')\n",
    "clusts = probe_insertions.fetch(format='frame').reset_index()\n",
    "\n",
    "# put metrics into df columns from the blob (feature request: can these be added as attributes instead?)\n",
    "for kix, k in enumerate(['ks2_label']):\n",
    "    tmp_var = []\n",
    "    for id, c in clusts.iterrows():\n",
    "        if k in c['metrics'].keys():\n",
    "            tmp = c['metrics'][k]\n",
    "        else:\n",
    "            tmp = np.nan\n",
    "        tmp_var.append(tmp)\n",
    "    clusts[k] = tmp_var\n",
    "    \n",
    "# hofer and mrsic-flogel probes are shared\n",
    "clusts['lab_name'] = clusts['lab_name'].str.replace('mrsicflogellab','swclab')\n",
    "clusts['lab_name'] = clusts['lab_name'].str.replace('hoferlab','swclab')\n",
    "clusts.lab_name.unique()\n",
    "\n",
    "clusts['probe_name'] = clusts['lab_name'] + ', ' + clusts['probe_model_name'] + ': ' + clusts['probe_serial_number']\n",
    "clusts_summ = clusts.groupby(['lab_name', 'probe_name', 'session_start_time', 'ks2_label'])['session_date'].count().reset_index()\n",
    "\n",
    "# use recording session number instead of date\n",
    "clusts_summ['recording'] = clusts_summ.groupby(['probe_name']).cumcount() + 1\n",
    "\n",
    "## overall distribution of neurons per session\n",
    "g = sns.FacetGrid(data=clusts_summ, hue='ks2_label', palette='Set2')\n",
    "g.map(sns.distplot, \"session_date\", bins=np.arange(10, 500, 15), hist=True, rug=False, kde=False).add_legend()\n",
    "for ax in g.axes.flatten():\n",
    "    ax.axvline(x=60, color='seagreen', linestyle=\"--\")\n",
    "    \n",
    "g.set_xlabels('Number of KS2 neurons')\n",
    "g.set_ylabels('Number of sessions')\n",
    "g.savefig(os.path.join(figpath, 'probe_yield_allrecs_goodsessions.pdf'))\n",
    "\n",
    "print('TOTAL YIELD (from good sessions) SO FAR:')\n",
    "clusts.groupby(['ks2_label'])['ks2_label'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. how does probe yield in the repeated site differ between mice/experimenters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes_rs = (ephys.ProbeTrajectory & 'insertion_data_source = \"Planned\"'\n",
    "             & 'x BETWEEN -2400 AND -2100' & 'y BETWEEN -2100 AND -1900' & 'theta BETWEEN 14 AND 16')\n",
    "\n",
    "clust = ephys.DefaultCluster * ephys.DefaultCluster.Metrics * probes_rs * subject.SubjectLab() * subject.Subject()\n",
    "clust = clust.proj('cluster_amp', 'cluster_depth', 'firing_rate', 'subject_nickname', 'lab_name','metrics',\n",
    "                   'x', 'y', 'theta', 'phi', 'depth')\n",
    "clusts = clust.fetch(format='frame').reset_index()\n",
    "clusts['col_name'] = clusts['lab_name'] + ', ' + clusts['subject_nickname']\n",
    "\n",
    "# put metrics into df columns from the blob\n",
    "for kix, k in enumerate(clusts['metrics'][0].keys()):\n",
    "    tmp_var = []\n",
    "    for id, c in clusts.iterrows():\n",
    "        if k in c['metrics'].keys():\n",
    "            tmp = c['metrics'][k]\n",
    "        else:\n",
    "            tmp = np.nan\n",
    "        tmp_var.append(tmp)\n",
    "    clusts[k] = tmp_var\n",
    "\n",
    "clusts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", context=\"paper\")\n",
    "g, axes = plt.subplots(1,1,figsize=(4,4))\n",
    "df = clusts.groupby(['col_name', 'ks2_label']).ks2_label.count()\n",
    "df.unstack().plot.barh(ax=axes, stacked=True, legend=True, colormap='Pastel2')\n",
    "axes.axvline(x=60, color='seagreen', linestyle=\"--\")\n",
    "axes.set_ylabel('')\n",
    "sns.despine(trim=True)   \n",
    "plt.xlabel('Number of KS2 neurons')\n",
    "g.savefig(os.path.join(figpath, 'probe_yield_rs.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## firing rate as a function of depth\n",
    "print('plotting')\n",
    "g = sns.FacetGrid(data=clusts, col='col_name', col_wrap=4, hue='ks2_label',\n",
    "                  palette='Pastel2', col_order=sorted(clusts.col_name.unique()))\n",
    "g.map(sns.scatterplot, \"firing_rate\", \"cluster_depth\", alpha=0.5).add_legend()\n",
    "g.set_titles('{col_name}')\n",
    "g.set_xlabels('Firing rate (spks/s)')\n",
    "g.set_ylabels('Depth')\n",
    "plt.tight_layout()\n",
    "sns.despine(trim=True)\n",
    "g.savefig(os.path.join(figpath, 'neurons_rsi_firingrate.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iblenv] *",
   "language": "python",
   "name": "conda-env-iblenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
